{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,learning_curve, validation_curve\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from LogClass import LogObj\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ConnMySQLDB import MySQLDB\n",
    "from Voice_Dectection_Utils import VoiceDetectionUtils\n",
    "\n",
    "# init\n",
    "logFile = LogObj('.','logFile')\n",
    "mySQLDB = MySQLDB(logFile)\n",
    "utils = VoiceDetectionUtils(logFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"select * from t_device40 where rec_datetime >= '2019-07-19 20:39:00' and rec_datetime <= '2019-07-19 20:56:00';\"\n",
    "ErrSQL = [\n",
    "      \"select * from t_device41 where rec_datetime >= '2019-07-20 16:31:30' and rec_datetime <= '2019-07-20 16:49:00';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-21 11:28:30' and rec_datetime <= '2019-07-21 11:40:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-22 22:14:00' and rec_datetime <= '2019-07-22 22:23:00';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-23 15:19:00' and rec_datetime <= '2019-07-23 15:28:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-23 16:23:00' and rec_datetime <= '2019-07-23 17:02:00';\"\n",
    "      #,\"select * from t_device41 where rec_datetime >= '2019-07-23 20:38:30' and rec_datetime <= '2019-07-22 20:42:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-23 22:49:00' and rec_datetime <= '2019-07-23 23:03:30';\"\n",
    "      #,\"select * from t_device41 where rec_datetime >= '2019-07-24 03:14:30' and rec_datetime <= '2019-07-24 03:22:00';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-24 04:36:00' and rec_datetime <= '2019-07-24 04:38:00';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-24 06:39:00' and rec_datetime <= '2019-07-24 06:43:00';\"\n",
    "      #,\"select * from t_device41 where rec_datetime >= '2019-07-24 16:37:00' and rec_datetime <= '2019-07-24 17:15:00';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-25 14:43:30' and rec_datetime <= '2019-07-25 14:48:00';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-26 16:56:30' and rec_datetime <= '2019-07-26 17:17:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-27 11:50:30' and rec_datetime <= '2019-07-27 12:19:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-28 16:07:30' and rec_datetime <= '2019-07-28 16:25:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-08-05 16:29:30' and rec_datetime <= '2019-08-05 16:34:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-08-07 21:28:30' and rec_datetime <= '2019-08-07 21:33:00';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-08-07 22:06:30' and rec_datetime <= '2019-08-07 22:16:00';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-08-09 02:26:00' and rec_datetime <= '2019-08-09 02:33:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-08-14 06:05:30' and rec_datetime <= '2019-08-14 06:26:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-08-14 06:38:30' and rec_datetime <= '2019-08-14 06:46:30';\"];\n",
    "\n",
    "#抓取資料\n",
    "OutputErrRaw = mySQLDB.extractData('192.168.11.115',3306,'Ac0u5Tasiai2','XY\"S/?>wt5K\"2','acoustics',ErrSQL)\n",
    "\n",
    "\n",
    "SQL = [\"select * from t_device41 where rec_datetime >= '2019-07-19 21:02:30' and rec_datetime <= '2019-07-19 21:59:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-19 22:18:30' and rec_datetime <= '2019-07-19 22:32:00';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-19 22:53:00' and rec_datetime <= '2019-07-19 22:59:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-21 12:00:00' and rec_datetime <= '2019-07-21 12:09:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-22 22:35:30' and rec_datetime <= '2019-07-22 22:59:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-23 17:13:00' and rec_datetime <= '2019-07-23 17:59:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-24 03:26:30' and rec_datetime <= '2019-07-24 03:59:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-24 04:43:00' and rec_datetime <= '2019-07-24 05:59:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-24 17:29:30' and rec_datetime <= '2019-07-24 18:05:00';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-24 18:12:00' and rec_datetime <= '2019-07-24 18:28:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-26 17:36:30' and rec_datetime <= '2019-07-26 18:29:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-27 13:07:00' and rec_datetime <= '2019-07-27 13:20:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-28 16:43:00' and rec_datetime <= '2019-07-28 17:59:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-07-31 11:21:00' and rec_datetime <= '2019-07-31 12:02:30';\"\n",
    "      ,\"select * from t_device41 where rec_datetime >= '2019-08-07 21:42:00' and rec_datetime <= '2019-08-07 21:59:30';\"];\n",
    "\n",
    "#抓取正常資料\n",
    "OutputNormalRaw = mySQLDB.extractData('192.168.11.115',3306,'Ac0u5Tasiai2','XY\"S/?>wt5K\"2','acoustics',SQL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "changedSQL = [\"select * from t_device40 where rec_datetime >= '2019-09-17 17:02:30' and rec_datetime <= '2019-09-17 17:59:30';\",\n",
    "             \"select * from t_device40 where rec_datetime >= '2019-09-20 11:02:30' and rec_datetime <= '2019-09-20 12:00:30';\"];\n",
    "\n",
    "#抓取正常資料\n",
    "changedOutputNormalRaw = mySQLDB.extractData('192.168.11.115',3306,'Ac0u5Tasiai2','XY\"S/?>wt5K\"2','acoustics',changedSQL)\n",
    "\n",
    "changedErrSQL = [\"select * from t_device40 where rec_datetime >= '2019-09-29 15:13:00' and rec_datetime <= '2019-09-29 15:16:05';\"\n",
    "                 ,\"select * from t_device40 where rec_datetime >= '2019-09-24 07:34:00' and rec_datetime <= '2019-09-24 07:38:00';\"\n",
    "                 , \"select * from t_device40 where rec_datetime >= '2019-09-23 21:59:00' and rec_datetime <= '2019-09-23 22:00:30';\"\n",
    "                 , \"select * from t_device40 where rec_datetime >= '2019-09-23 14:54:00' and rec_datetime <= '2019-09-23 14:59:00';\" #小沖\n",
    "                 , \"select * from t_device40 where rec_datetime >= '2019-09-20 12:51:00' and rec_datetime <= '2019-09-20 12:54:00';\" #沒沖水\n",
    "                ];\n",
    "\n",
    "#抓取異常資料\n",
    "changedOutputErrRaw = mySQLDB.extractData('192.168.11.115',3306,'Ac0u5Tasiai2','XY\"S/?>wt5K\"2','acoustics',changedErrSQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轉換資料格式\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "OutputNormalTrans = utils.transRawData(OutputNormalRaw)\n",
    "OutputErrTrans = utils.transRawData(OutputErrRaw)\n",
    "OutputNormalTrans = OutputNormalTrans.iloc[:,20:76]\n",
    "OutputErrTrans = OutputErrTrans.iloc[:,20:76]\n",
    "\n",
    "#正規化\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "tempModel = std_scaler.fit(OutputNormalTrans)\n",
    "dataScaled = tempModel.transform(OutputNormalTrans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分辨正常和異常PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99).fit(dataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74146551 0.09101297 0.04077532 0.0267347  0.01705679 0.01333902\n",
      " 0.01251621 0.00670347 0.00605875 0.00514326 0.00468595 0.00359469\n",
      " 0.00326281 0.00312346 0.00256468 0.00232965 0.00219475 0.00194546\n",
      " 0.00157576 0.00147057 0.00124756 0.00116606 0.00109818]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings_p = pca.components_.T\n",
    "eigenvalues = pca.explained_variance_\n",
    "#t-square\n",
    "hotelling_t2s = np.array([xi.dot(loadings_p)\n",
    "                            .dot(np.diag(eigenvalues ** -1))\n",
    "                            .dot(loadings_p.T)\n",
    "                            .dot(xi.T)\n",
    "                          for xi in dataScaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.94561619494755"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold=np.max(hotelling_t2s)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試\n",
    "dfScaled = tempModel.transform(OutputErrTrans)\n",
    "hotelling_t2s = np.array([xi.dot(loadings_p)\n",
    "                            .dot(np.diag(eigenvalues ** -1))\n",
    "                            .dot(loadings_p.T)\n",
    "                            .dot(xi.T)\n",
    "                          for xi in dfScaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5135135135135135"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hotelling_t2s[hotelling_t2s>threshold])/len(hotelling_t2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0:00:00.000987 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5652173913043478"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 使用位置改變後資料\n",
    "changedOutputNormalTrans = utils.transRawData(changedOutputNormalRaw)\n",
    "changedOutputErrTrans = utils.transRawData(changedOutputErrRaw)\n",
    "changedOutputNormalTrans = changedOutputNormalTrans.iloc[:,20:76]\n",
    "changedOutputErrTrans = changedOutputErrTrans.iloc[:,20:76]\n",
    "\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "std = std_scaler.fit(changedOutputNormalTrans)\n",
    "changedOutputNormalTrans = std.transform(changedOutputNormalTrans)\n",
    "\n",
    "pca = PCA(n_components=0.99).fit(changedOutputNormalTrans)\n",
    "\n",
    "loadings_p = pca.components_.T\n",
    "eigenvalues = pca.explained_variance_\n",
    "#t-square\n",
    "hotelling_t2s = np.array([xi.dot(loadings_p)\n",
    "                            .dot(np.diag(eigenvalues ** -1))\n",
    "                            .dot(loadings_p.T)\n",
    "                            .dot(xi.T)\n",
    "                          for xi in dataScaled])\n",
    "\n",
    "threshold=np.max(hotelling_t2s)\n",
    "threshold\n",
    "\n",
    "# 測試\n",
    "start_time = datetime.datetime.now()\n",
    "changedOutputErrTrans = std.transform(changedOutputErrTrans)\n",
    "hotelling_t2s = np.array([xi.dot(loadings_p)\n",
    "                            .dot(np.diag(eigenvalues ** -1))\n",
    "                            .dot(loadings_p.T)\n",
    "                            .dot(xi.T)\n",
    "                          for xi in changedOutputErrTrans])\n",
    "end_time=datetime.datetime.now()\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "len(y_pred_test[y_pred_test==-1])/len(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分辨正常和異常One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf',\n",
       "      max_iter=-1, nu=0.01, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.OneClassSVM(nu=0.01, kernel='rbf')\n",
    "clf.fit(dataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0:00:00.000997 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 測試\n",
    "start_time = datetime.datetime.now()\n",
    "dfScaled = tempModel.transform(OutputErrTrans)\n",
    "y_pred_test = clf.predict(dfScaled)\n",
    "end_time=datetime.datetime.now()\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8378378378378378"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_test[y_pred_test==-1])/len(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0:00:00.001339 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5652173913043478"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 使用位置改變後資料\n",
    "changedOutputNormalTrans = utils.transRawData(changedOutputNormalRaw)\n",
    "changedOutputErrTrans = utils.transRawData(changedOutputErrRaw)\n",
    "changedOutputNormalTrans = changedOutputNormalTrans.iloc[:,20:76]\n",
    "changedOutputErrTrans = changedOutputErrTrans.iloc[:,20:76]\n",
    "\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "std = std_scaler.fit(changedOutputNormalTrans)\n",
    "changedOutputNormalTrans = std.transform(changedOutputNormalTrans)\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.OneClassSVM(nu=0.01, kernel='rbf')\n",
    "clf.fit(changedOutputNormalTrans)\n",
    "\n",
    "# 測試\n",
    "start_time = datetime.datetime.now()\n",
    "changedOutputErrTrans = std.transform(changedOutputErrTrans)\n",
    "y_pred_test = clf.predict(changedOutputErrTrans)\n",
    "end_time=datetime.datetime.now()\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "len(y_pred_test[y_pred_test==-1])/len(y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
